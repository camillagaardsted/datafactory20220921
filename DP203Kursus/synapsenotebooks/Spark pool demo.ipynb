{
  "description": null,
  "sessionProperties": {
    "driverMemory": "28g",
    "driverCores": 4,
    "executorMemory": "28g",
    "executorCores": 4,
    "numExecutors": 2
  },
  "metadata": {
    "kernelspec": {
      "name": "synapse_pyspark",
      "display_name": "Synapse PySpark"
    },
    "language_info": {
      "name": "python",
      "codemirror_mode": null
    },
    "a365ComputeOptions": {
      "id": "/subscriptions/64e64ad4-c73a-4e76-932e-45cba3506c45/resourceGroups/dk/providers/Microsoft.Synapse/workspaces/synapse20220920/bigDataPools/mysparkpool",
      "name": "mysparkpool",
      "type": "Spark",
      "endpoint": "https://synapse20220920.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/mysparkpool",
      "auth": {
        "type": "AAD",
        "authResource": "https://dev.azuresynapse.net",
        "authHeader": null
      },
      "sparkVersion": "3.2",
      "nodeCount": 10,
      "cores": 4,
      "memory": 28,
      "extraHeader": null
    },
    "sessionKeepAliveTimeout": 30,
    "saveOutput": true,
    "synapse_widget": {
      "version": "0.1",
      "state": {}
    },
    "enableDebugMode": false
  },
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "microsoft": {
          "language": "python"
        }
      },
      "source": [
        "%%pyspark\r\n",
        "df = spark.read.load('abfss://raspdata@datalakesu20220919.dfs.core.windows.net/sensor=1984/year=2022/month=09/data2022_09_19_11_48_42.csv', format='csv'\r\n",
        "## If header exists uncomment line below\r\n",
        ", header=True\r\n",
        ")\r\n",
        "display(df.limit(10))"
      ],
      "attachments": null,
      "outputs": [
        {
          "name": null,
          "execution_count": null,
          "output_type": "display_data",
          "text": null,
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": null,
              "session_id": null,
              "statement_id": null,
              "state": "session_error",
              "livy_statement_state": null,
              "queued_time": "2022-09-20T11:35:42.9859073Z",
              "session_start_time": "2022-09-20T11:35:43.0476944Z",
              "execution_start_time": null,
              "execution_finish_time": null,
              "spark_jobs": null
            },
            "text/plain": "StatementMeta(, , , SessionError, )"
          },
          "metadata": {}
        },
        {
          "name": null,
          "execution_count": null,
          "output_type": "error",
          "text": null,
          "data": null,
          "metadata": null
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "microsoft": {
          "language": "python"
        }
      },
      "source": [
        "%%pyspark\r\n",
        "df = spark.read.load('abfss://matador@datalakesu20220919.dfs.core.windows.net/matador_skjern.json', format='json')\r\n",
        "display(df.limit(10))"
      ],
      "attachments": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "df = spark.read.load('abfss://matador@asadatalake2prbthc.dfs.core.windows.net/*.json', format='json',multiline=True)\r\n",
        "display(df.limit(10))"
      ],
      "attachments": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "from pyspark.sql.functions import explode\r\n",
        "childrenDF=df.select('lastName',explode('children').alias('childrenflat'))\r\n",
        "childrenDF.show()"
      ],
      "attachments": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "newDF=childrenDF.select('lastName', 'childrenflat.firstName','childrenflat.gender','childrenflat.grade')\r\n",
        "newDF.show()\r\n",
        ""
      ],
      "attachments": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "microsoft": {
          "language": "sparksql"
        }
      },
      "source": [
        "%%sql\r\n",
        "CREATE DATABASE synapsesparkDB"
      ],
      "attachments": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "newDF.write.format(\"parquet\").saveAsTable('synapsesparkdb.matadorChildren')"
      ],
      "attachments": null,
      "outputs": []
    }
  ],
  "entityState": null,
  "renameOperationDetails": null,
  "targetSparkConfiguration": null
}